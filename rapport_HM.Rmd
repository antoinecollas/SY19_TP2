---
title: "SY19 TP07"
output: html_notebook
---

```{r include=FALSE}
set.seed(100)
setwd("D:/Documents/GI04/SY19/tp07/data")
data <- read.csv(file="astronomy_train.csv")
```

```{r include=FALSE}
library("corrplot")
#install.packages("sampling")
#install.packages("FactoMineR")
library(sampling)
library(FactoMineR)
library(MASS)
```

#Données astronomiques

TO DO !!!!!
a faire nettoyer le code pour cet exercice et intégrer le code de l'arbre de décision pour comparer les résultats
tester acp ou kernel PCA


## 1- Analyse exploratoire du jeu de données

### a) Observation du jeu de données

On dispose d'un jeu de données avec 5000 observations sur 18 variables, parmi lesquelles 17 variables prédictives et une variable à prédire : "class". La classe d'un objet astronomique peut être : "STAR", "GALAXY" ou "QSO".

Quelle est la proportion des observations dans chaque classe ?

```{r echo=FALSE}
table <- table(data$class)
print(table)
```

Les proprotions ne sont pas de 1/3 pour chaque classe, on a nettement moins d'observations de la classe "QSO".

On observe les différentes valeurs pour chaque variable.

```{r echo=FALSE}
sapply(as.data.frame(sapply(data, as.factor)), nlevels)
```

On observe que les variables "objid" et "rerun" ne possèdent qu'une seule valeur. Elles n'apportent aucune information.

Le observations sont aussi décrites par des variables de type "identifiant" : "specobjid" et "fiberid". Plusieurs observations comportent le même "sepcobjid" ou "fiberid" ; ces identifiants n'étant pas uniques dans le jeu de données, ils pourraient porter de l'information. Il est vraisemblable que "specobjid" soit un identifiant de l'objet astronomique observé.

On remarque que pour un même "specobjid", ni la variable "class" ni la variable "mjd" ne varient. Un même objet astronomique peut alors être observé avec différentes valeurs de "mjd" ou "fiberid". 

### b) Préparation du jeu de données

D'après les observations que nous avons réalisées précédemmment, nous décidons de retirer certaines variables prédictives de notre futur modèle. On se débarrassera des variables "objid", "rerun", "specobjid", "fiberid" et "mjd". 

En effet, nous souhaitons a priori prédire la classe pour des objets qui n'ont pas encore été observés ; l'information "specobjid" nous est alors inutile.

En revanche, les variables qui semblent plutôt correspondre à des données de physique sont elles intéressantes pour la prédiction : "ra", "dec", "u", "g", "r", "i", "z", "redshift". Quant aux variables "run", field", "camcol" et "plate", nous ne sommes pas sûrs de leur intérêt. Nous pourrons tester nos modèles avec et sans apprentissage de ces variables.

```{r echo=FALSE}
data.clean <- as.data.frame(data[,!(colnames(data) %in% c("objid", "rerun","specobjid", "fiberid", "mjd"))])
data.clean2 <- as.data.frame(data[,!(colnames(data) %in% c("objid", "rerun","specobjid", "fiberid", "mjd", "run", "field", "camcol", "plate"))])
```

### c) Corrélations entre les variables

```{r echo=FALSE}
corrplot(cor(data.clean[,!(colnames(data.clean) %in% c("class"))]), type="upper", order="hclust", method="number")

```

On observe de fortes corrélations principalement entre les variables "r","i","z" et "g".

## 2- Séparation des jeux d'apprentissage et de test

On utilisera 2/3 des observations pour l'apprentissage, et 1/3 pour le jeu de test. 

Pour le jeu d'apprentissage, on souhaiterait conserver les mêmes proportions do'bservations pour chaque classe (afin que le jeu d'apprentissage soit représentatif du jeu de données complet). Pour cela on se sert de la fonction "strata" disponible dans le package "sampling".

```{r echo=FALSE}

n <- nrow(data.clean)
p <- ncol(data.clean)

ratio <- 2/3

repartition <- data.frame(rbind(floor(table*ratio)))
data.strata <- strata(data.clean2, stratanames="class", size=c(repartition$STAR, repartition$GALAXY, repartition$QSO), method="srswor")

print(table(data.strata$class))

data.train <- data.clean2[data.strata$ID_unit,]
data.test <- data.clean2[-data.strata$ID_unit,]

ntrain <- nrow(data.train)
ntest<- nrow(data.test)
```


On utilise un tirage sans remise avec équiprobabilité à l'intérieur de chaque classe, c'est-à-dire que pour une même classe toutes les observations ont la même probabilité d'être tirées.


## 2- Modèles

### a) LDA

On souhaite tester plusieurs modèles discriminants.Commençons par l'analyse discriminante linéaire (LDA).

```{r}
#Test des performances de LDA sans cross validation
data.lda <- lda(formula = class~., data=data.train)

data.plda <- predict(data.lda, newdata=data.test)

table(data.plda$class,data.test$class)
mean(data.plda$class==data.test$class)
```


On teste les performances de ce modèle avec deux ensembles de variables prédictives, l'un avec les quatre variables "run", field", "camcol" et "plate", l'autre sans. Pour pouvoir comparer les deux scores de façon fiable, il faut répéter le calcul de l'erreur de test plusieurs fois.

```{r echo=TRUE}

#Avec cross validation
K<-50
folds=sample(1:K,n,replace=TRUE)
CV<-rep(0,10)
for(i in (1:10)){
  for(k in (1:K)){
    
    data.strata <- strata(data.clean2, stratanames="class", size=c(repartition$STAR, repartition$GALAXY,  repartition$QSO), method="srswor")

    data.train <- data.clean2[data.strata$ID_unit,]
    data.test <- data.clean2[-data.strata$ID_unit,]
    
    data.lda <- lda(formula = class~., data=data.train)
    
    data.plda <- predict(data.lda, newdata=data.test)
    CV[i]<-sum(data.plda$class==data.test$class)
  }
CV[i]<-CV[i]/ntest
}
print(mean(CV))
```

Avec 9 variables, on obtient un score de 0.9136091 sur l'ensemble de test avec k-fold validation pour k=10.
Avec 13 variables, nous obtenons un score de 0.9259592.

#### Hypothèses de l'analyse discriminante linéaire

L'ADL présuppose les conditions suivantes : 
- distribution gaussienne multivariée des variables prédictives
- égalité des matrices de covariance de chaque classe

On vérifie que nos données sont bien en adéquation avec ces hypothèses.
### b) QDA


QDA
```{r}

library(sampling)
data2$class <- as.factor(data2$class)
n <- nrow(data2)
p <- ncol(data2)
table <- table(data2$class)
ratio <- 2/3
repartition <- data.frame(rbind(floor(table*ratio)))
print(repartition)
data.strata <- strata(data2, stratanames="class", size=c(repartition$STAR, repartition$GALAXY, repartition$QSO), method="srswor")
data.train <- data2[data.strata$ID_unit,]
data.test <- data2[-data.strata$ID_unit,]
r <- qda(formula = class~., data=data.train)
summary(r)
names(r)
plda <- predict(r, newdata=data.test)
table(plda$class,data.test$class)
mean(plda$class==data.test$class)
```

Both LDA and QDA assume the the predictor variables X are drawn from a multivariate Gaussian (aka normal) distribution.

LDA assumes equality of covariances among the predictor variables X across each all levels of Y. This assumption is relaxed with the QDA model.

LDA and QDA require the number of predictor variables (p) to be less than the sample size (n). Furthermore, its important to keep in mind that performance will severely decline as p approaches n. A simple rule of thumb is to use LDA & QDA on data sets where 


### c) NBA

### d) Arbre de décision

d'aorès le corrplot : corrélations -> réduire la dimension
acp (plutôt non supervisé) ou LDA (plutot supervisé, mais avec hypothèse de distribution gaussienne!)


```{r}
#install.packages("heplots")
library(heplots)
heplots::covEllipses(data2[,!(colnames(data2) %in% c("class"))], 
                     data2$class,
                     fill = TRUE, 
                     pooled = FALSE,
                      col = c("blue", "red","green"), 
                     variables = c(1:6, 12), 
                     fill.alpha = 0.05
)
```
```{r}
heplots::covEllipses(data2[,!(colnames(data2) %in% c("class"))], 
                     data2$class,
                     fill = TRUE, 
                     pooled = FALSE,
                      col = c("blue", "red","green"), 
                     variables = c(6:11, 12), 
                     fill.alpha = 0.05
)
```

on teste le 3eme precidteur d'analyse discriminanet (pa d'hypothèse de normalité)
```{r}
library(e1071)
r <- naiveBayes(formula = class~., data=data.train)
summary(r)
names(r)
plda <- predict(r, newdata=data.test)
table(plda,data.test$class)
mean(plda==data.test$class)
```

hypothèses du modèle naif : indépendance conditionnelle à la classe
pas d'hypothèse sur la distribution des données

on se débarasse de tous les entiers (en fait ils nous genent pour l'anakyse du test d'independance)
```{r}
#install.packages("bnlearn")
data3 <- data[, (colnames(data) %in% c("ra", "dec", "u", "g", "r", "i", "z", "redshift", "class"))]
library(bnlearn)
ci <- ci.test(data3[!colnames(data) %in% c("class"),])
names(ci)
ci$p.value
ci$statistic

```

réalise un test d'indépendance du khi-carré : la statisqtique calculée est le khi carré qui vaut presque 6 ici.
le nb de degré de liberté est le nb de catégories de X -1 multiplié par le nombre de cat de Y -1 et est donné par la variable parameters (14)


on choisit un seuil P = 5% de chances de se tromper. Dans la table, le khi carré théorique vaut 6.57. La statistique du test est inférieure donc
Si le khi-carré calculé est inférieur au khi-carré théorique : indépendance

tester le nba seulement avec ces var car apparemment indep
(on imagine que si on ajoute les autres var il y a des relations de dependance qui s'ajoutent)

```{r}
data3.train <- data3[data.strata$ID_unit,]
data3.test <- data3[-data.strata$ID_unit,]
r <- naiveBayes(formula = class~., data=data3.train)
summary(r)
names(r)
plda <- predict(r, newdata=data3.test)
table(plda,data3.test$class)
mean(plda==data3.test$class)
```

test de la lda :
```{r}
library(MASS)
r <- qda(formula = class~., data=data.train[,!(colnames(data) %in% c("specobjid", "fiberid"))])
summary(r)
names(r)
plda <- predict(r, newdata=data.test,  interval = "confidence")
table(plda$class,data.test$class)
mean(plda$class==data.test$class)
```

```{r}
data.star <- data[data$class=="STAR",!(colnames(data) %in% c("class"))]
data.galaxy <- data[data$class=="GALAXY",!(colnames(data) %in% c("class"))]
data.qso <- data[data$class=="QSO",!(colnames(data) %in% c("class"))]

corr.star <- cor(data.star)
corr.galaxy <- cor(data.galaxy)
corr.qso <- cor(data.qso)

diff.corr.Star.Galaxy <- corr.star - corr.galaxy
diff.corr.Star.qso <- corr.star - corr.qso
diff.corr.Galaxy.qso <- corr.galaxy - corr.qso

norm(diff.corr.Star.Galaxy, type = "f") # Frobenius norm
norm(diff.corr.Star.qso, type = "f") # Frobenius norm
norm(diff.corr.Galaxy.qso, type = "f") # Frobenius norm

```



The skewness and kurtosis have long been suggested for detecting non-normality in the univariate setting. For general multivariate data, Mardia constructed two statistics for measuring multivariate skewness and kurtosis.

The skewness test rejects the hypothesis of normality if MS is too large, and the test based on the centralized kurtosis statistic MK rejects the null hypothesis of normality if its absolute value |MK| is too large, that is, it exceeds the appropriate critical value. Both the skewness and kurtosis tests are simple and informative, and provide specific information about non-normality of the data
```{r}
#Test multi normalité du jeu de donnée

library(MVN)
result <- mvn(data = data.train[,!(colnames(data) %in% c("specobjid", "fiberid","class", "run", "camcol", "field", "plate", "mdj"))], mvnTest = "mardia")
result$multivariateNormality

```

Les Arbres 

```{r}
library(rpart)

tree <-  rpart(class ~., data = data.train[,!(colnames(data) %in% c("specobjid", "fiberid","plate"))])
plotcp(tree)

plot(tree)
text(tree)

plda <- predict(r, newdata=data.test)
table(plda$class,data.test$class)
mean(plda$class==data.test$class)

summary(tree)
```





### b) Analyse en composantes principales (? peut être pas utile...)

Nous avons vu précédemment qu'il existait des variables très corrélées dans le jeu de données. Nous sommes alors tentés de réaliser une ACP afin d'obtenir un jeu de données décorrélé.

```{r}
data.pca <- PCA(data.clean[,!(colnames(data.clean) %in% c("class"))], graph = FALSE)

eig.val <- data.pca$eig
barplot(eig.val[, 2], 
        names.arg = 1:nrow(eig.val), 
        main = "Variances Explained by PCs (%)",
        xlab = "Principal Components",
        ylab = "Percentage of variances",
        col ="steelblue")
# Add connected line segments to the plot
lines(x = 1:nrow(eig.val), eig.val[, 2], 
      type = "b", pch = 19, col = "red")

plot(data.pca, choix = "var", autoLab = "yes")
```
