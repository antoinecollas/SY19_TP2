---
title: "TP7"
output:
  pdf_document: default
  html_notebook: default
---
```{r}
source(file="cv_classif.R")
RECHERCHE_HYPERPARAMETRES <- FALSE
```
# Astronomy
## Chargement des données
```{r}
astronomy <- read.table('data/astronomy_train.csv', sep = ",", header = TRUE)
colnames(astronomy)[14] <- "y"
ncol(astronomy)
nrow(astronomy)
```

## Présentation des données
Ce problème est un problème de classification comportant 3 classes avec les effectifs suivants:
```{r, echo=FALSE}
table(astronomy["y"])
```

Ce jeu de données comporte 5000 individus pour 17 variables. Toutes les variables sont quantitatives.

Les variables 'objid' et 'rerun' n'ont qu'une seule valeur. Nous les retirons puiqu'elles ne nous servirons pas à discriminer les 3 classes.
```{r}
for (colname in colnames(astronomy)){
  if (length(unique(astronomy[,colname])) < 10) {
    print(colname)
    print(length(unique(astronomy[,colname])))
  }
}
astronomy <- astronomy[,-which(names(astronomy)=="objid")]
astronomy <- astronomy[,-which(names(astronomy)=="rerun")]
```

Nous centrons et réduisons les variables. En effet certaines variables comme 'specobjid' sont en 10^18 alors que d'autres variables sont en 10^-4 comme 'redshift'.
```{r}
astronomy <- cbind(data.frame(scale(astronomy[,-which(names(astronomy)=="y")], center = TRUE, scale = TRUE)), astronomy[,which(names(astronomy)=="y")])
colnames(astronomy)[ncol(astronomy)] <- "y"
head(astronomy, 3)
```

## Séparation des données en entrainement/test
Nous séparons les données en un ensemble d'entrainement sur lequel nous allons tester tout nos modèles et un ensemble de test qui nous permettra d'évaluer l'erreur pour le modèle que nous aurons retenu. Avant de conserver la même séparation des données à chaque execution du notebook nous fixons le générateur de nombre aléatoires (seed).
```{r}
set.seed(42)
train_size <- nrow(astronomy) * (2/3)
train <- sample(1:nrow(astronomy), size = train_size)
astronomy_train <- astronomy[train,]
nrow(astronomy_train)
ncol(astronomy_train)
```

##Analyses discriminantes
```{r}
set.seed(123)
#validation croisée sur l'ensemble d'entrainement
res <- data.frame("Erreur"=rep(0,3), "Ecart type"=rep(0,3))
res[1,] <- CV_eval('adl', astronomy_train)
res[2,] <- CV_eval('adq', astronomy_train)
res[3,] <- CV_eval('bayesien_naif', astronomy_train)
colnames(res) <- c("Erreur", "Ecart type")
row.names(res) <- c("ADL", "ADQ", "Bayesien naif")
```
Nous obtenons les erreurs suivantes:

```{r, echo=FALSE}
knitr::kable(res)
```

L'analyse discriminante quadratique est l'algorithme le plus performant des trois modèles testés précédemment. Les modèles plus complexes fonctionnent donc bien sur ce jeu de données. Nous testons donc SVM avec différents noyaux.

#SVM

Les SVM ont l'hyperparamètre C: si C est faible alors le SVM aura une large marge quitte à mal classer certains points (on peut dans ce cas se retrouver dans un cas de sous entrainement). De manière opposé, si C est grand alors le SVM classifira bien beaucoup de points mais aura une faible marge et donc risque un sur entrainement. Nous cherchons le meilleur compromis.

Nous cherchons l'hyperparamètre C minimisant l'erreur de classification pour un noyau linéaire.

##Optimisation C
```{r}
if (RECHERCHE_HYPERPARAMETRES){
  set.seed(123)
  C_err_min <- 0
  C_liste <- (1:5)^5
  erreurs_C <- rep(0, length(C_liste))
  for (i in 1:length(C_liste)){
    hyperparametres <- list(kernel="vanilla", C=C_liste[i], kpar=list())
    erreurs_C[i] <- CV_eval('svc', astronomy_train, hyperparametres)[1]
  }
  plot(C_liste, erreurs_C)
  C <- C_liste[which.min(erreurs_C)]
}else{
  C <- 5^5
}
```

##SVM à noyaux
Les différents noyaux vont nous permettre de trouver des fontières de décision non linéaires.

Nous testons trois noyaux pour les SVM:
- noyau linéaire ('vanilladot') qui n'a pas d'hyperparamètres
- noyau polynomial pour lequel il faut régler le degré du noyau. Nous testons cet hyperparamètre pour des valeurs de 2 à 5. Nous retenons le degré donnant la plus faible erreur par validation croisée.
- noyau gaussien

L'idéal serait d'optimiser C pour différents noyaux. Cependant chaque noyau possède d'autres hyperparamètres et essayer toutes les combinaisons se révèle trop couteux en calculs. Par conséquent nous conservons la valeur trouvée avec le noyau linéaire.

```{r}
if (RECHERCHE_HYPERPARAMETRES){
  set.seed(123)
  degre_err_min <- 0
  degres <- 2:5 
  erreurs_degres <- rep(0, length(degres)) 
  for (i in 1:length(degres)){
    print(degres[i])
    hyperparametres <- list(kernel="polydot", kpar=list(degree=degres[i]), C=C)
    erreurs_degres[i] <- CV_eval('svc', astronomy_train, hyperparametres)[1]
  }
  plot(degres, erreurs_degres)
  degre <- which.min(erreurs_degres)
}else{
  degre <- 2
}
```

```{r}
set.seed(123)
res <- data.frame("Erreur"=rep(Inf,3), "Ecart type"=rep(Inf,3))

#validation croisée sur l'ensemble d'entrainement
#noyau linéaire
hyperparametres <- list(kernel="vanilladot", kpar=list(), C=C)
res[1,] <- CV_eval('svc', astronomy_train, hyperparametres)
#noyau polynomial
hyperparametres <- list(kernel="polydot", kpar=list(degree=degre), C=C)
res[2,] <- CV_eval('svc', astronomy_train, hyperparametres)
#noyau rbf
hyperparametres <- list(kernel="rbfdot", kpar=list(), C=C)
res[3,] <- CV_eval('svc', astronomy_train, hyperparametres)
colnames(res) <- c("Erreur", "Ecart type")
row.names(res) <- c("vanilla", "poly", "rbf")
```
Nous obtenons les erreurs suivantes:

```{r, echo=FALSE}
knitr::kable(res)
```

#K plus proches voisins
Nous testons les K plus proches voisins. Pour cela nous devons chercher le meilleur K, c'est à dire le K pour lequel notre erreur de validation croisée est minimale. Nous évaluons les valeurs de K entre 1 et 100.

```{r}
set.seed(123)
res <- data.frame("Erreur"=rep(Inf,1), "Ecart type"=rep(Inf,1))
if(RECHERCHE_HYPERPARAMETRES){
  list_k <- (1:10)*40
  for (k in list_k){
    hyperparametres <- list(K=k)
    temp <- CV_eval('knn', astronomy_train, hyperparametres)
    if(temp[1]<res[1]){
      k_min <- k
      res[1,1] <- temp[1]
      res[1,2] <- temp[2]
    }
  }
}else{
  k <- 40
  hyperparametres <- list(K=k)
  temp <- CV_eval('knn', astronomy_train, hyperparametres)
  res[1,1] <- temp[1]
  res[1,2] <- temp[2]
}
```

```{r, echo=FALSE}
knitr::kable(res)
```
