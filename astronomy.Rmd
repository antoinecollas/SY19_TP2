---
title: "R Notebook"
output: html_notebook
---
```{r}
source(file="cv_classif.R")
```
# Astronomy
## Chargement des données
```{r}
astronomy <- read.table('data/astronomy_train.csv', sep = ",", header = TRUE)
colnames(astronomy)[14] <- "y"
ncol(astronomy)
nrow(astronomy)
```
## Présentation des données
Classification: 3 classes
Nombre d'individus: 5000
Nombre de variables: 17
Toutes les variables sont quantitatives.

Les variables 'objid' et 'rerun' n'ont qu'une seule valeur. Nous les retirons puiqu'elles ne nous servirons pas à discriminer les 3 classes.
```{r}
for (colname in colnames(astronomy)){
  if (length(unique(astronomy[,colname])) < 10) {
    print(colname)
    print(length(unique(astronomy[,colname])))
  }
}
astronomy <- astronomy[,-which(names(astronomy)=="objid")]
astronomy <- astronomy[,-which(names(astronomy)=="rerun")]
astronomy
```

Nous centrons et réduisons les variables. En effet certaines variables comme 'specobjid' sont en 1O^18 alors que d'autres variables sont en 10^-4 comme 'redshift'.
```{r}
astronomy <- cbind(data.frame(scale(astronomy[,-which(names(astronomy)=="y")], center = TRUE, scale = TRUE)), astronomy[,which(names(astronomy)=="y")])
colnames(astronomy)[ncol(astronomy)] <- "y"
astronomy
```

## Séparation des données en entrainement/test
```{r}
set.seed(42)
train_size <- nrow(astronomy) * (2/3)
train <- sample(1:nrow(astronomy), size = train_size)
astronomy_train <- astronomy[train,]
nrow(astronomy_train)
ncol(astronomy_train)
```

##Analyses discriminantes
```{r}
set.seed(123)
#validation croisée sur l'ensemble d'entrainement
res <- data.frame("Erreur"=rep(0,3), "Ecart type"=rep(0,3))
res[1,] <- CV_eval('adl', astronomy_train)
res[2,] <- CV_eval('adq', astronomy_train)
res[3,] <- CV_eval('bayesien_naif', astronomy_train)
colnames(res) <- c("Erreur", "Ecart type")
row.names(res) <- c("ADL", "ADQ", "Bayesien naif")
```
Nous obtenons les erreurs suivantes:

```{r, echo=FALSE}
knitr::kable(res)
```

#K plus proches voisins
Nous testons les K plus proches voisins. Pour cela nous devons chercher le meilleur K, c'est à dire le K pour lequel notre erreur de validation croisée est minimale. Nous évaluons les valeurs de K entre 1 et 100.

```{r}
set.seed(123)
res <- data.frame("Erreur"=rep(Inf,1), "Ecart type"=rep(Inf,1))
list_k <- (1:10)*40
for (k in list_k){
  hyperparametres <- list(K=k)
  temp <- CV_eval('knn', astronomy_train, hyperparametres)
  if(temp[1]<res[1]){
    k_min <- k
    res[1,1] <- temp[1]
    res[1,2] <- temp[2]
  }
}
```

```{r, echo=FALSE}
knitr::kable(res)
```
